{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prof-atritiack/visao-computacional-huggingface/blob/main/huggingface_visao_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8769a03",
      "metadata": {
        "id": "b8769a03"
      },
      "source": [
        "\n",
        "# **Hugging Face - Visão Computacional (Colab com Visualização)**\n",
        "\n",
        "Este notebook apresenta um fluxo **didático e direto** para trabalhar com modelos de **classificação** e **detecção de objetos** do Hugging Face.  \n",
        "O padrão de exibição de imagens segue o mesmo usado no notebook do **YOLO**, com `cv2_imshow`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73825134",
      "metadata": {
        "id": "73825134"
      },
      "source": [
        "## **1. Instalação das dependências**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f9f43d",
      "metadata": {
        "collapsed": true,
        "id": "64f9f43d"
      },
      "outputs": [],
      "source": [
        "!pip install -U huggingface_hub transformers pillow torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "krPwmNF6MA9g"
      },
      "id": "krPwmNF6MA9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0385a8e3",
      "metadata": {
        "id": "0385a8e3"
      },
      "source": [
        "## **2. Login no Hugging Face Hub**\n",
        "Use o token salvo nos *secrets* do Colab (`HF_TOKEN`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef63c5a1",
      "metadata": {
        "id": "ef63c5a1"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "token = userdata.get('HF_TOKEN')  # defina o token nos secrets do Colab\n",
        "login(token=token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14fedcfe",
      "metadata": {
        "id": "14fedcfe"
      },
      "source": [
        "## **3. Preparação das imagens de teste**\n",
        "As imagens devem ser colocadas na pasta `datasets/imagens/`. Será usada a imagem `exemplo.jpg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811c58ce",
      "metadata": {
        "id": "811c58ce"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "IMAGES_DIR = Path(\"datasets/imagens\")\n",
        "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exemplo_imagem = IMAGES_DIR / \"exemplo.jpg\"\n",
        "\n",
        "if exemplo_imagem.exists():\n",
        "    print(\"Imagem encontrada:\", exemplo_imagem)\n",
        "else:\n",
        "    print(\"Adicione uma imagem chamada 'exemplo.jpg' em datasets/imagens/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9ae8e8",
      "metadata": {
        "id": "da9ae8e8"
      },
      "source": [
        "## **4. Classificação de imagens**\n",
        "Será usado o modelo `google/vit-base-patch16-224`. O resultado mostrará a imagem e os rótulos previstos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "fNLodVdQLFEF"
      },
      "id": "fNLodVdQLFEF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CLF = 'google/vit-base-patch16-224'\n",
        "clf = pipeline(task='image-classification', model=MODEL_CLF)"
      ],
      "metadata": {
        "id": "LlXDmZ4uLJFE"
      },
      "id": "LlXDmZ4uLJFE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f556b7b",
      "metadata": {
        "id": "2f556b7b"
      },
      "outputs": [],
      "source": [
        "if exemplo_imagem.exists():\n",
        "    img = Image.open(exemplo_imagem).convert('RGB')\n",
        "    preds = clf(str(exemplo_imagem))\n",
        "    print('Resultados da classificação:')\n",
        "    for p in preds:\n",
        "        print(f\"{p['label']}: {100*(p['score']):.2f} %\")\n",
        "    # Exibir imagem\n",
        "    # img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "    # cv2_imshow(img_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be480c6",
      "metadata": {
        "id": "5be480c6"
      },
      "source": [
        "## **5. Detecção de objetos**\n",
        "Será usado o modelo `facebook/detr-resnet-50`. As caixas serão desenhadas na imagem e exibidas no Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageDraw"
      ],
      "metadata": {
        "id": "MP9dA9BjMgT7"
      },
      "id": "MP9dA9BjMgT7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DET = 'facebook/detr-resnet-50'\n",
        "detector = pipeline(task='object-detection', model=MODEL_DET)"
      ],
      "metadata": {
        "id": "hgUyXMFjMjBA"
      },
      "id": "hgUyXMFjMjBA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659ad0e0",
      "metadata": {
        "id": "659ad0e0"
      },
      "outputs": [],
      "source": [
        "if exemplo_imagem.exists():\n",
        "    img = Image.open(exemplo_imagem).convert('RGB')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    dets = detector(str(exemplo_imagem))\n",
        "    print('Resultados da detecção:')\n",
        "    for d in dets:\n",
        "        box = d['box']\n",
        "        draw.rectangle([(box['xmin'], box['ymin']), (box['xmax'], box['ymax'])], outline='red', width=3)\n",
        "        draw.text((box['xmin'], box['ymin']-10), f\"{d['label']} {d['score']:.2f}\", fill='red')\n",
        "        print(f\"{d['label']} ({100*(d['score']):.2f} %) -> {box}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir imagem processada no Colab\n",
        "img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "cv2_imshow(img_cv)"
      ],
      "metadata": {
        "id": "VC9983awMpCk"
      },
      "id": "VC9983awMpCk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "84b919ad",
      "metadata": {
        "id": "84b919ad"
      },
      "source": [
        "## **6. Uso da API HTTP do Hugging Face**\n",
        "Exemplo de como enviar a imagem para a API de inferência do Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "eUpABDR7PNbX"
      },
      "id": "eUpABDR7PNbX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token do Colab Secrets\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "if HF_TOKEN is None:\n",
        "    HF_TOKEN = input(\"⚠️ Token Hugging Face não encontrado nos secrets. Cole seu HF_TOKEN: \")\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
        "    \"Content-Type\": \"application/octet-stream\"\n",
        "}"
      ],
      "metadata": {
        "id": "CrtS5GNXPTXx"
      },
      "id": "CrtS5GNXPTXx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_MODEL = MODEL_CLF\n",
        "API_URL = f\"https://api-inference.huggingface.co/models/{API_MODEL}\""
      ],
      "metadata": {
        "id": "Aa3g09MaPPsr"
      },
      "id": "Aa3g09MaPPsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if exemplo_imagem.exists():\n",
        "    with open(exemplo_imagem, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    resp = requests.post(API_URL, headers=headers, data=data)\n",
        "\n",
        "    print(\"Status da requisição:\", resp.status_code)\n",
        "    try:\n",
        "        resposta = resp.json()\n",
        "        print(\"Resposta da API:\")\n",
        "        print(json.dumps(resposta, indent=2, ensure_ascii=False))\n",
        "    except Exception as e:\n",
        "        print(\"Erro ao interpretar resposta:\", e)\n",
        "        print(resp.text)\n",
        "else:\n",
        "    print(\"Adicione a imagem exemplo.jpg em datasets/imagens/\")"
      ],
      "metadata": {
        "id": "9GAY0h9OPF30"
      },
      "id": "9GAY0h9OPF30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image, ImageDraw"
      ],
      "metadata": {
        "id": "xzsXS9lLTcob"
      },
      "id": "xzsXS9lLTcob",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exemplo_imagem = IMAGES_DIR / \"person.jpg\"  # troque para o nome do arquivo desejado"
      ],
      "metadata": {
        "id": "_wI6tdwKThVf"
      },
      "id": "_wI6tdwKThVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if exemplo_imagem.exists():\n",
        "    img = Image.open(exemplo_imagem).convert(\"RGB\")\n",
        "    print(\"Imagem carregada:\", exemplo_imagem)\n",
        "\n",
        "    # ==== 2. Usar a API HTTP do Hugging Face para detecção ====\n",
        "    API_MODEL = MODEL_DET  # definido antes (facebook/detr-resnet-50)\n",
        "    API_URL = f\"https://api-inference.huggingface.co/models/{API_MODEL}\"\n",
        "\n",
        "    with open(exemplo_imagem, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    resp = requests.post(\n",
        "        API_URL,\n",
        "        headers={**headers, \"Content-Type\": \"image/jpeg\"},\n",
        "        data=data\n",
        "    )\n",
        "\n",
        "    print(\"Status da requisição:\", resp.status_code)\n",
        "    resposta = resp.json()\n",
        "    print(\"Resposta bruta da API (Detecção):\")\n",
        "    print(json.dumps(resposta, indent=2, ensure_ascii=False))\n",
        "\n",
        "    # ==== 3. Desenhar bounding boxes na imagem com cores variadas ====\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    cores = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"cyan\", \"magenta\", \"yellow\"]\n",
        "\n",
        "    if isinstance(resposta, list):\n",
        "        for i, d in enumerate(resposta):\n",
        "            if \"box\" in d:\n",
        "                box = d[\"box\"]\n",
        "                cor = cores[i % len(cores)]  # alterna entre as cores da lista\n",
        "                draw.rectangle(\n",
        "                    [(box[\"xmin\"], box[\"ymin\"]), (box[\"xmax\"], box[\"ymax\"])],\n",
        "                    outline=cor, width=3\n",
        "                )\n",
        "                draw.text(\n",
        "                    (box[\"xmin\"], box[\"ymin\"]-10),\n",
        "                    f\"{d['label']} {d['score']:.2f}\",\n",
        "                    fill=cor\n",
        "                )\n",
        "    else:\n",
        "        print(\"⚠️ A resposta não contém uma lista de detecções.\")\n",
        "\n",
        "    # ==== 4. Exibir imagem com bounding boxes no Colab ====\n",
        "    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "    cv2_imshow(img_cv)\n",
        "else:\n",
        "    print(\"⚠️ Imagem não encontrada:\", exemplo_imagem)\n"
      ],
      "metadata": {
        "id": "V0DCo5RCR2M8"
      },
      "id": "V0DCo5RCR2M8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}